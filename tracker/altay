import argparse
import os
import cv2
from CountsPerSec import CountsPerSec
from VideoGet import VideoGet
from VideoShow import VideoShow
import cv2
import math
import numpy as np
import time





frameWidth = 720
frameHeight = 480

def Dark_channel(img, r):
    win_size = 2 * r + 1
    B, G, R = cv2.split(img)
    temp = cv2.min(cv2.min(B, G), R)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (win_size, win_size))
    dark = cv2.erode(temp, kernel)
    return dark

def AL_estimation(img, dark_channel):
    h, w = img.shape[:2]
    img_size = h * w
    num_pixel = int(max(math.floor(img_size / 1000), 1))

    img_temp = img.reshape(img_size, 3)
    dark_temp = dark_channel.reshape(img_size, 1)

    index = dark_temp[:, 0].argsort()
    index_use = index[img_size - num_pixel:]

    AL_sum = np.zeros([1, 3])
    for i in range(num_pixel):
        AL_sum = AL_sum + img_temp[index_use[i]]

    AL = AL_sum / num_pixel
    thread = np.array([[0.95, 0.95, 0.95]])
    A = cv2.min(AL, thread)
    return A

def Trans_estimation(img, A, r, omega):

    img_temp = np.empty(img.shape, img.dtype)
    for i in range(3):
        img_temp[:, :, i] = img[:, :, i] / A[0, i]
    trans = 1 - omega * Dark_channel(img_temp, r)
    return trans

def Guided_filter(I, p, r, eps):

    mean_I = cv2.boxFilter(I, cv2.CV_64F, (r, r))
    mean_p = cv2.boxFilter(p, cv2.CV_64F, (r, r))
    corr_I = cv2.boxFilter(I * I, cv2.CV_64F, (r, r))
    corr_Ip = cv2.boxFilter(I * p, cv2.CV_64F, (r, r))

    var_I = corr_I - mean_I * mean_I
    cov_Ip = corr_Ip - mean_I * mean_p

    a = cov_Ip / (var_I + eps)
    b = mean_p - a * mean_I

    mean_a = cv2.boxFilter(a, cv2.CV_64F, (r, r))
    mean_b = cv2.boxFilter(b, cv2.CV_64F, (r, r))

    q = mean_a * I + mean_b  #

    return q

def dehaze(img, r, n=20, thre=0.001, eps=0.001, omega=0.9):
    # img_pro = img.astype('float64')/255
    img_pro = np.float64(img) / 255
    J_dark = Dark_channel(img_pro, r)
    A = AL_estimation(img_pro, J_dark)
    t = Trans_estimation(img_pro, A, r, omega)

    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img_gray = np.float64(img_gray) / 255

    t_ref = Guided_filter(img_gray, t, r * n, eps)

    t_thre = cv2.max(t_ref, thre)
    result = np.empty(img_pro.shape, img_pro.dtype)
    for i in range(3):
        result[:, :, i] = (img_pro[:, :, i] - A[0, i]) / t_thre + A[0, i]

    return result








def putIterationsPerSec(frame, iterations_per_sec):
    """
    Add iterations per second text to lower-left corner of a frame.
    """

    cv2.putText(frame, "{:.0f} iterations/sec".format(iterations_per_sec),
        (10, 450), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255))
    return frame

def noThreading(source=0):
    """Grab and show video frames without multithreading."""

    cap = cv2.VideoCapture(source)
    cps = CountsPerSec().start()

    while True:
        grabbed, frame = cap.read()
        if not grabbed or cv2.waitKey(1) == ord("q"):
            break

        frame = putIterationsPerSec(frame, cps.countsPerSec())
        cv2.imshow("Video", frame)
        cps.increment()

def threadVideoGet(source=0):
    """
    Dedicated thread for grabbing video frames with VideoGet object.
    Main thread shows video frames.
    """

    video_getter = VideoGet(source).start()
    cps = CountsPerSec().start()

    while True:
        if (cv2.waitKey(1) == ord("q")) or video_getter.stopped:
            video_getter.stop()
            break

        frame = video_getter.frame
        frame = putIterationsPerSec(frame, cps.countsPerSec())
        cv2.imshow("Video", frame)
        cps.increment()

def threadVideoShow(source=0):
    """
    Dedicated thread for showing video frames with VideoShow object.
    Main thread grabs video frames.
    """

    cap = cv2.VideoCapture(source)
    (grabbed, frame) = cap.read()
    video_shower = VideoShow(frame).start()
    cps = CountsPerSec().start()

    while True:
        (grabbed, frame) = cap.read()
        if not grabbed or video_shower.stopped:
            video_shower.stop()
            break

        frame = putIterationsPerSec(frame, cps.countsPerSec())
        video_shower.frame = frame
        cps.increment()


frame_count = 0

def threadBoth(source=0):
    """
    Dedicated thread for grabbing video frames with VideoGet object.
    Dedicated thread for showing video frames with VideoShow object.
    Main thread serves only to pass frames between VideoGet and
    VideoShow objects/threads.
    """
    
    fps_start = 0
    fps =0

    

    video_getter = VideoGet(source).start()
    video_shower = VideoShow(video_getter.frame).start()
    cps = CountsPerSec().start()

    while True:
        if video_getter.stopped or video_shower.stopped:
            video_shower.stop()
            video_getter.stop()
            break
	
	
        frame = video_getter.frame
        frame = cv2.resize(frame, (360, 211))
        
        J = dehaze(frame, 5, n=8)
        
        
        frame = cv2.resize(frame, (frameWidth, frameHeight))
        J = cv2.resize(J, (frameWidth, frameHeight))
        
        fps_end = time.time()
        
        J = cv2.flip(J, 1)	
        
        time_diff = fps_end - fps_start
        fps = 1 / (time_diff)
        fps_start = fps_end
        
        print(fps)
        
        frame = putIterationsPerSec(frame, cps.countsPerSec())
        video_shower.frame = J
        cps.increment()

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--source", "-s", default=0,
        help="Path to video file or integer representing webcam index"
            + " (default 0).")
    ap.add_argument("--thread", "-t", default="none",
        help="Threading mode: get (video read in its own thread),"
            + " show (video show in its own thread), both"
            + " (video read and video show in their own threads),"
            + " none (default--no multithreading)")
    args = vars(ap.parse_args())

    # If source is a string consisting only of integers, check that it doesn't
    # refer to a file. If it doesn't, assume it's an integer camera ID and
    # convert to int.
    if (
        isinstance(args["source"], str)
        and args["source"].isdigit()
        and not os.path.isfile(args["source"])
    ):
        args["source"] = int(args["source"])

    if args["thread"] == "both":
        threadBoth(args["source"])
    elif args["thread"] == "get":
        threadVideoGet(args["source"])
    elif args["thread"] == "show":
        threadVideoShow(args["source"])
    else:
        noThreading(args["source"])

if __name__ == "__main__":
    main()
